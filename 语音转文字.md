# 语音转文字

## 方案一, 对音频信号了解

- 安装的库

```shell
# numpy
pip install numpy

# matplotlib
pip install matplotlib

# scipy
pip install scipy

# pyaudio
pip install pyaudio 
## error :
	## sudo apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg libav-tools
	## 如果有问题, 把 libav-tools ffmpeg 删了

pip install wave


# 安装 tkinter
sudo apt-get install python3-tk
```

### 录音

```python
import pyaudio
import wave

chunk = 1024  # Record in chunks of 1024 samples # 记录单位
sample_format = pyaudio.paInt16  # 16 bits per sample # 样本类型
channels = 2 # 声道数据
fs = 44100  # Record at 44100 samples per second # 样本速度
seconds = 3 # 记录时间
filename = "output.wav"

p = pyaudio.PyAudio()  # Create an interface to PortAudio

# print all the devices
for i in range(p.get_device_count()):
    print(p.get_device_info_by_index(i))
    # 使用指定设备
    # stream = p.open(format=sample_format,
    #                 channels=channels,
    #                 rate=fs,
    #                 frames_per_buffer=chunk,
    #                 input_device_index=i,
    #                 input=True)
#   

stream = p.open(format=sample_format,
                channels=channels,
                rate=fs,
                frames_per_buffer=chunk,
                input=True)

frames = []  # Initialize array to store frames

print('Recording')

# Store data in chunks for 3 seconds
for i in range(0, int(fs / chunk * seconds)):
    data = stream.read(chunk)
    frames.append(data)

# Stop and close the stream 
stream.stop_stream()
stream.close()
# Terminate the PortAudio interface
p.terminate()

print('Finished recording')

# Save the recorded data as a WAV file
wf = wave.open(filename, 'wb')
wf.setnchannels(channels)
wf.setsampwidth(p.get_sample_size(sample_format))
wf.setframerate(fs)
wf.writeframes(b''.join(frames))
wf.close()
```

### 音频可视化一， 图

```python
import numpy as np
import matplotlib
# 使用 TkAgg install tkinter
matplotlib.use('TkAgg')

import matplotlib.pyplot as plt
from scipy.io import wavfile


# 读取音频文件
frequency_sampling, audio_signal = wavfile.read("output.wav")


print('\nSignal shape:', audio_signal.shape)
print('Signal Datatype:', audio_signal.dtype)
print('Signal duration:', round(audio_signal.shape[0] / float(frequency_sampling), 2), 'seconds')

print('\n frequency_sampling:', frequency_sampling)


audio_signal = audio_signal / np.power(2, 15) # 归一化

# audio_signal = audio_signal [:100] # 取前100个数据
time_axis = 1000 * np.arange(0, len(audio_signal), 1) / float(frequency_sampling) # 时间轴

print('\nTime Axis in ms', time_axis.shape) # 时间轴
# print('Audio Signal in time domain', audio_signal) # 音频信号

# plt.plot([1,2,3,4], [1,4,9,16])
# plt.show()

plt.plot(time_axis, audio_signal, color='blue')
plt.xlabel('Time (milliseconds)')
plt.ylabel('Amplitude')
plt.title('Input audio signal')
plt.show()
```
